

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>} &mdash; 运维开发修炼之路</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../../',
              VERSION:'1.0.0',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: ''
          };
      </script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> 小健_Java_Blog
          

          
            
            <img src="../../_static/my_java_study.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../Java/index.html">Java学习笔记</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">分布式系统架构案例(Java)</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">小健_Java_Blog</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>}</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/Distributed_Systems/01.分布式系统基础知识/03.Apache Kafka.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p># Apache Kafka</p>
<p>Apache Kafka 是一种高吞吐的分布式发布订阅消息系统，可以提供消息的持久化，即使数据以TB的消息存储也能够保持长时间的文档性能，同时Kafka也支持Hadoop并行数据加载。</p>
<p>## Apache Kafka的安装、配置、使用</p>
<p>### 1.下载安装</p>
<p>安装包的下载地址为 &lt;<a class="reference external" href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a>&gt;&gt;</p>
<p>这里下载的是kafka_2.13-2.5.0.tgz</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">tar</span> <span class="pre">-xzf</span> <span class="pre">kafka_2.13-2.5.0.tgz</span>
<span class="pre">cd</span> <span class="pre">kafka_2.13-2.5.0.</span>
<span class="pre">`</span></code></p>
<p>解压安装包kafka_2.13-2.5.0.tgz到任意安装目录，如果是unix系统，则执行安装目录下的bin目录下的脚本，如果是windows系统，则执行bin/windows目录下的脚本。</p>
<p>### 2.启动kafka server服务</p>
<p>因Kafka使用了ZooKeeper，所以，首先启动ZooKeeper（Kafka自带打包和配置好了的ZooKeeper），执行：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">[root&#64;px-master</span> <span class="pre">kafka_2.13-2.5.0]#</span> <span class="pre">./bin/zookeeper-server-start.sh</span> <span class="pre">config/zookeeper.properties</span>
<span class="pre">`</span></code></p>
<p>现在启动Kafka服务：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">[root&#64;px-master</span> <span class="pre">kafka_2.13-2.5.0]#</span> <span class="pre">./bin/kafka-server-start.sh</span> <span class="pre">config/server.properties</span> <span class="pre">&amp;</span>
<span class="pre">`</span></code></p>
<p>### 3.创建topic</p>
<p>创建一个名为“test”的Topic，只有一个分区和一个备份：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">[root&#64;px-master</span> <span class="pre">kafka_2.13-2.5.0]#</span> <span class="pre">./bin/kafka-topics.sh</span> <span class="pre">--create</span> <span class="pre">--zookeeper</span> <span class="pre">localhost:2181</span> <span class="pre">--replication-factor</span> <span class="pre">1</span> <span class="pre">--partitions</span> <span class="pre">1</span> <span class="pre">--topic</span> <span class="pre">test</span>
<span class="pre">Created</span> <span class="pre">topic</span> <span class="pre">test.</span>
<span class="pre">`</span></code></p>
<p>创建好之后，可以通过运行以下命令，查看已创建的topic信息：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">[root&#64;px-master</span> <span class="pre">kafka_2.13-2.5.0]#</span> <span class="pre">./bin/kafka-topics.sh</span> <span class="pre">--list</span> <span class="pre">--zookeeper</span> <span class="pre">localhost:2181</span>
<span class="pre">test</span>
<span class="pre">`</span></code></p>
<p>除了手工创建topic，我们也可以配置直接的broker，当发布一个不存在的topic时，来自动创建topic。</p>
<p>### 4.发送消息</p>
<p>Kafka提供一个命令行的工具，可以从输入文件或者命令行中读取消息并发送给Kafka集群，每一行是一条消息。</p>
<p>运行Producer程序，然后在控制台输入几条消息到服务器。</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">[root&#64;px-master</span> <span class="pre">kafka_2.13-2.5.0]#</span> <span class="pre">bin/kafka-console-producer.sh</span> <span class="pre">--broker-list</span> <span class="pre">localhost:9092</span> <span class="pre">--topic</span> <span class="pre">test</span>
<span class="pre">&gt;asasas</span>
<span class="pre">&gt;asasas</span>
<span class="pre">&gt;saasa</span>
<span class="pre">&gt;aasdsa</span>
<span class="pre">&gt;asa</span>
<span class="pre">`</span></code></p>
<p>### 5.启动消费者</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">[root&#64;px-master</span> <span class="pre">kafka_2.13-2.5.0]#</span>&#160; <span class="pre">bin/kafka-console-consumer.sh</span> <span class="pre">--bootstrap-server</span> <span class="pre">localhost:9092</span> <span class="pre">--topic</span> <span class="pre">test</span> <span class="pre">--from-beginning</span>
<span class="pre">This</span> <span class="pre">is</span> <span class="pre">another</span> <span class="pre">message</span>
<span class="pre">This</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">message</span>
<span class="pre">This</span> <span class="pre">is</span> <span class="pre">another</span> <span class="pre">message</span>
<span class="pre">aaa</span>
<span class="pre">aaaaaaaaaaaaaaaaaaaaa</span>
<span class="pre">aaaaaaaaaaaaaaa</span>
<span class="pre">bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb</span>
<span class="pre">cccccccccccccccccc</span>
<span class="pre">asasas</span>
<span class="pre">asasas</span>
<span class="pre">saasa</span>
<span class="pre">aasdsa</span>
<span class="pre">asa</span>
<span class="pre">`</span></code></p>
<p>如果无法启动，根据提示，可能需要加zookeeper：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">bin/kafka-console-consumer.sh</span> <span class="pre">--bootstrap-server</span> <span class="pre">localhost:9092</span> <span class="pre">--zookeeper</span> <span class="pre">localhost:2181</span> <span class="pre">--topic</span> <span class="pre">test</span> <span class="pre">--from-beginning</span>
<span class="pre">`</span></code></p>
<p>如果在2台不同的终端上运行上述命令，那么当运行Producer时，Consumer就能消费到Producer发送的消息。</p>
<p>### 6.设置多个broker集群</p>
<p>对于Kafka来说，一个broker仅仅是一个集群的大小，即使多设置几个broker实例也不会有大的变化，为了演示效果，我们扩展集群到三个节点。</p>
<p>首先为每个broker创建一个配置文件：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">cp</span> <span class="pre">config/server.properties</span> <span class="pre">config/server-1.properties</span>
<span class="pre">$</span> <span class="pre">cp</span> <span class="pre">config/server.properties</span> <span class="pre">config/server-2.properties</span>
<span class="pre">`</span></code></p>
<p>编辑这些新建的文件。</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">cat</span> <span class="pre">config/server-1.properties</span> <span class="pre">|grep</span> <span class="pre">-v</span> <span class="pre">&quot;^#&quot;|grep</span> <span class="pre">-v</span> <span class="pre">&quot;^$&quot;</span>
<span class="pre">broker.id=1</span>
<span class="pre">listeners=PLAINTEXT://:9093</span>
<span class="pre">log.dirs=/tmp/kafka-logs-1</span>
<span class="pre">`</span></code></p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">cat</span> <span class="pre">config/server-2.properties</span> <span class="pre">|grep</span> <span class="pre">-v</span> <span class="pre">&quot;^#&quot;|grep</span> <span class="pre">-v</span> <span class="pre">&quot;^$&quot;</span>
<span class="pre">broker.id=2</span>
<span class="pre">listeners=PLAINTEXT://:9094</span>
<span class="pre">log.dirs=/tmp/kafka-logs-2</span>
<span class="pre">`</span></code></p>
<p>broker.id是集群中每个节点的唯一且永久的名称，端口和日志分区是因为多个broker现在在同一台机器上运行，我们防止broker在同一端口上注册和覆盖对方数据。</p>
<p>我们已经运行了Zookeeper和一个Kafka节点，所以只需要再启动2个新的Kafka节点：</p>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>shell
$ ./bin/kafka-server-start.sh config/server-1.properties &amp;</p>
<p>$ ./bin/kafka-server-start.sh config/server-2.properties &amp;
<a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
<p>现在创建一个topic，把备份设置为3</p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>shell
$ bin/kafka-topics.sh &#8211;create &#8211;zookeeper localhost:2181 &#8211;replication-factor 3 &#8211;partitions 1 &#8211;topic my-replic
ated-topic</p>
<p>Created topic my-replicated-topic.
<a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a></p>
<p>现在已经有了一个集群了，运行“describe topics”命令可以查看每个集群的状态。</p>
<p><a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>shell
$ bin/kafka-topics.sh &#8211;describe &#8211;zookeeper localhost:2181 &#8211;topic my-replicated-topic</p>
<dl class="docutils">
<dt>Topic: my-replicated-topic      PartitionCount: 1       ReplicationFactor: 3    Configs:</dt>
<dd>Topic: my-replicated-topic      Partition: 0    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2</dd>
</dl>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a></p>
<p>这是一个解释输出，第一行是所有分区的摘要，每一个线提供一个分区信息，因为只有一个分区，所以只有一条线，其中。</p>
<ul class="simple">
<li>Leader &#8212;该节点负责所有指定分区的读和写，每个节点的领导都是随机选择的；</li>
<li>Replicas&#8212;备份的节点，无论该节点是否是leader或者目前是否还活着，只是显示；</li>
<li>Isr&#8212;-备份节点的集合，也就是活着的节点集合。</li>
</ul>
<p>查看之前创建的单节点：</p>
<p><a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a>shell
$ bin/kafka-topics.sh &#8211;describe &#8211;zookeeper localhost:2181 &#8211;topic test
Topic: test     PartitionCount: 1       ReplicationFactor: 1    Configs:</p>
<blockquote>
<div>Topic: test     Partition: 0    Leader: 0       Replicas: 0     Isr: 0</div></blockquote>
<p><a href="#id29"><span class="problematic" id="id30">``</span></a><a href="#id31"><span class="problematic" id="id32">`</span></a></p>
<p>由于刚才创建的topic没有Replicas，所以是0。</p>
<p>发布一些信息在新的topic上：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">bin/kafka-console-producer.sh</span> <span class="pre">--broker-list</span> <span class="pre">localhost:9092</span> <span class="pre">--topic</span> <span class="pre">myreplicated-topic</span>
<span class="pre">&gt;dasdasdasda</span>
<span class="pre">[2020-07-14</span> <span class="pre">11:48:34,231]</span> <span class="pre">WARN</span> <span class="pre">[Producer</span> <span class="pre">clientId=console-producer]</span> <span class="pre">Error</span> <span class="pre">while</span> <span class="pre">fetching</span> <span class="pre">metadata</span> <span class="pre">with</span> <span class="pre">correlation</span> <span class="pre">id</span> <span class="pre">3</span> <span class="pre">:</span> <span class="pre">{myreplicated-topic=LEAD</span>
<span class="pre">ER_NOT_AVAILABLE}</span> <span class="pre">(org.apache.kafka.clients.NetworkClient)a&gt;dadasdasdasd</span>
<span class="pre">&gt;my</span> <span class="pre">test</span> <span class="pre">message</span> <span class="pre">1</span>
<span class="pre">&gt;my</span> <span class="pre">test</span> <span class="pre">message</span> <span class="pre">2</span>
<span class="pre">&gt;adsdsa</span>
<span class="pre">`</span></code></p>
<p>现在消费这些信息：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">bin/kafka-console-consumer.sh</span> <span class="pre">--bootstrap-server</span> <span class="pre">localhost:9092</span> <span class="pre">--topic</span> <span class="pre">myreplicated-topic</span> <span class="pre">--from-beginning</span>
<span class="pre">dasdasdasda</span>
<span class="pre">adadasdasdasd</span>
<span class="pre">my</span> <span class="pre">test</span> <span class="pre">message</span> <span class="pre">1</span>
<span class="pre">my</span> <span class="pre">test</span> <span class="pre">message</span> <span class="pre">2</span>
<span class="pre">adsdsa</span>
<span class="pre">`</span></code></p>
<p>要测试集群的容错，kill掉leader，由于Broker1是当前的leader，被kill掉也就是Broker 1：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">ps</span> <span class="pre">aux</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">server-1.properties</span>
<span class="pre">$</span> <span class="pre">kill</span> <span class="pre">-9</span> <span class="pre">3025</span>
<span class="pre">`</span></code></p>
<p>备节点之一成为新的leader，而Broker 1 已经不在同步备份集合里了：</p>
<p><a href="#id33"><span class="problematic" id="id34">``</span></a><a href="#id35"><span class="problematic" id="id36">`</span></a>shell
$ bin/kafka-topics.sh &#8211;describe &#8211;zookeeper localhost:2181 &#8211;topic my-replicated-topic
Topic: my-replicated-topic      PartitionCount: 1       ReplicationFactor: 3    Configs:</p>
<blockquote>
<div>Topic: my-replicated-topic      Partition: 0    Leader: 0       Replicas: 1,0,2 Isr: 0,2</div></blockquote>
<p><a href="#id37"><span class="problematic" id="id38">``</span></a><a href="#id39"><span class="problematic" id="id40">`</span></a></p>
<p>但是消息仍然没丢</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">bin/kafka-console-consumer.sh</span> <span class="pre">--bootstrap-server</span> <span class="pre">localhost:9092</span> <span class="pre">--topic</span> <span class="pre">myreplicated-topic</span> <span class="pre">--from-beginning</span>
<span class="pre">dasdasdasda</span>
<span class="pre">adadasdasdasd</span>
<span class="pre">my</span> <span class="pre">test</span> <span class="pre">message</span> <span class="pre">1</span>
<span class="pre">my</span> <span class="pre">test</span> <span class="pre">message</span> <span class="pre">2</span>
<span class="pre">adsdsa</span>
<span class="pre">sdasdas</span>
<span class="pre">`</span></code></p>
<p>### 7.kafka指令大全</p>
<p><a href="#id41"><span class="problematic" id="id42">``</span></a><a href="#id43"><span class="problematic" id="id44">`</span></a>shell
bin/kafka-topics.sh &#8211;zookeeper localhost:2181 &#8211;list
//查看列表有那些topics</p>
<p>sh bin/kafka-topics.sh &#8211;delete &#8211;zookeeper localhost:2181 &#8211;topic sparkDemo
//删除topics：sparkDemo</p>
<p>bin/kafka-topics.sh &#8211;create &#8211;zookeeper localhost:2181 &#8211;replication-factor 1 &#8211;partitions 3 &#8211;topic sparkDemo
//创建topics：sparkDemo</p>
<p>bin/kafka-server-start.sh -daemon config/server.properties
//启动kafka</p>
<p>bin/kafka-console-producer.sh &#8211;broker-list localhost:9092 &#8211;topic HelloWor ld
//启动生产者</p>
<p>bin/kafka-console-consumer.sh &#8211;zookeeper localhost:2181 &#8211;topic HelloWorld
//启动消费者
<a href="#id45"><span class="problematic" id="id46">``</span></a><a href="#id47"><span class="problematic" id="id48">`</span></a></p>
<p>### 8.用Java(idea)来测试kafka中的生产者和消费者</p>
<p>idea环境
打开idea并且创建maven项目。（不会的自己去百度）
<strong>pow.xml</strong>：</p>
<p><a href="#id49"><span class="problematic" id="id50">``</span></a><a href="#id51"><span class="problematic" id="id52">`</span></a>xml
&lt;?xml version=&#8221;1.0&#8221; encoding=&#8221;UTF-8&#8221;?&gt;
&lt;project xmlns=&#8221;<a class="reference external" href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a>&#8220;</p>
<blockquote>
<div><blockquote>
<div>xmlns:xsi=&#8221;http://www.w3.org/2001/XMLSchema-instance&#8221;
xsi:schemaLocation=&#8221;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&#8221;&gt;</div></blockquote>
<p>&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</p>
<p>&lt;groupId&gt;kafkaTest&lt;/groupId&gt;
&lt;artifactId&gt;kafkaTest&lt;/artifactId&gt;
&lt;version&gt;1.0.0&lt;/version&gt;
&lt;dependencies&gt;</p>
<blockquote>
<div><dl class="docutils">
<dt>&lt;dependency&gt;</dt>
<dd>&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt;
&lt;version&gt;1.0.0&lt;/version&gt;</dd>
</dl>
<p>&lt;/dependency&gt;
&lt;dependency&gt;</p>
<blockquote>
<div>&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
&lt;version&gt;1.0.0&lt;/version&gt;</div></blockquote>
<p>&lt;/dependency&gt;</p>
<dl class="docutils">
<dt>&lt;dependency&gt;</dt>
<dd>&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&lt;artifactId&gt;kafka-streams&lt;/artifactId&gt;
&lt;version&gt;1.0.0&lt;/version&gt;</dd>
</dl>
<p>&lt;/dependency&gt;</p>
</div></blockquote>
<p>&lt;/dependencies&gt;</p>
</div></blockquote>
<p>&lt;/project&gt;
<a href="#id53"><span class="problematic" id="id54">``</span></a><a href="#id55"><span class="problematic" id="id56">`</span></a></p>
<p>先关闭Kafka服务</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">bin/kafka-server-stop.sh</span> <span class="pre">config/server.properties</span> <span class="pre">&amp;</span>
<span class="pre">`</span></code></p>
<p>修改配置文件`vim config/server.properties`</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">$</span> <span class="pre">cat</span> <span class="pre">config/server.properties|grep</span> <span class="pre">-v</span> <span class="pre">&quot;^#&quot;|grep</span> <span class="pre">-v</span> <span class="pre">&quot;^$&quot;</span>
<span class="pre">broker.id=0</span>
<span class="pre">listeners=PLAINTEXT://172.16.60.190:9092</span>
<span class="pre">advertised.listeners=PLAINTEXT://172.16.60.190:9092</span>
<span class="pre">`</span></code></p>
<p>启动Kafka服务</p>
<p><a href="#id57"><span class="problematic" id="id58">``</span></a><a href="#id59"><span class="problematic" id="id60">`</span></a>shell
$ bin/kafka-server-start.sh config/server.properties  &amp;</p>
<p>$ bin/kafka-topics.sh &#8211;create &#8211;zookeeper localhost:2181 &#8211;replication-factor 1 &#8211;partitions 1 &#8211;topic HelloWorld
//创建topics：HelloWorld</p>
<p>$ bin/kafka-topics.sh &#8211;zookeeper localhost:2181 &#8211;list
<a href="#id61"><span class="problematic" id="id62">``</span></a><a href="#id63"><span class="problematic" id="id64">`</span></a></p>
<p>Java生产者代码</p>
<p><cite>ProducerDemo.java</cite></p>
<p><a href="#id65"><span class="problematic" id="id66">``</span></a><a href="#id67"><span class="problematic" id="id68">`</span></a>java
package kafka_Test;</p>
<p>import java.util.Properties;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;</p>
<dl class="docutils">
<dt>public class ProducerDemo {</dt>
<dd><dl class="first docutils">
<dt>public static void main(String[] args) {</dt>
<dd><p class="first">String topicName = &#8220;HelloWorld&#8221;;//这个是创建好的topic</p>
<p>// create instance for properties to access producer configs
Properties props = new Properties();</p>
<p>//这里是填你linux的ip地址:kafka的端口号
props.put(&#8220;bootstrap.servers&#8221;, &#8220;172.16.60.190:9092&#8221;);</p>
<p>//Set acknowledgements for producer requests.
props.put(&#8220;acks&#8221;, &#8220;all&#8221;);</p>
<p>//If the request fails, the producer can automatically retry,
props.put(&#8220;retries&#8221;, 0);</p>
<p>//Specify buffer size in config
props.put(&#8220;batch.size&#8221;, 16384);</p>
<p>//Reduce the no of requests less than 0
props.put(&#8220;linger.ms&#8221;, 1);</p>
<p>//The buffer.memory controls the total amount of memory available to the producer for buffering.
props.put(&#8220;buffer.memory&#8221;, 33554432);</p>
<p>props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);</p>
<dl class="docutils">
<dt>for (int i = 0; i &lt; 50; i++)</dt>
<dd>producer.send(new ProducerRecord&lt;String, String&gt;(topicName, Integer.toString(i), Integer.toString(i)));</dd>
</dl>
<p class="last">System.out.println(&#8220;Message sent successfully&#8221;);
producer.close();</p>
</dd>
</dl>
<p class="last">}</p>
</dd>
</dl>
<div class="section" id="id69">
<h1>}<a class="headerlink" href="#id69" title="Permalink to this headline">¶</a></h1>
<p>![](../../_static/kafk00001.png)</p>
<p>Java消费者代码 <cite>ConsumerDemo.java</cite></p>
<p><a href="#id70"><span class="problematic" id="id71">``</span></a><a href="#id72"><span class="problematic" id="id73">`</span></a>java
package kafka_Test;</p>
<p>import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;</p>
<p>import java.util.Arrays;
import java.util.Properties;</p>
<dl class="docutils">
<dt>public class ConsumerDemo {</dt>
<dd><p class="first">public static void main(String[] args) throws Exception {</p>
<blockquote>
<div><p>//Kafka consumer configuration settings
String topicName = &#8220;HelloWorld&#8221;;//创建好的topic
Properties props = new Properties();</p>
<p>props.put(&#8220;bootstrap.servers&#8221;, &#8220;172.16.60.190:9092&#8221;);//地址和端口号
props.put(&#8220;group.id&#8221;, &#8220;test&#8221;);
props.put(&#8220;enable.auto.commit&#8221;, &#8220;true&#8221;);
props.put(&#8220;auto.commit.interval.ms&#8221;, &#8220;1000&#8221;);
props.put(&#8220;session.timeout.ms&#8221;, &#8220;30000&#8221;);
props.put(&#8220;key.deserializer&#8221;, StringDeserializer.class.getName());
props.put(&#8220;value.deserializer&#8221;, StringDeserializer.class.getName());
KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);</p>
<p>//Kafka Consumer subscribes list of topics here.
consumer.subscribe(Arrays.asList(topicName));</p>
<p>//print the topic name
System.out.println(&#8220;Subscribed to topic &#8221; + topicName);
int i = 0;
while (true) {</p>
<blockquote>
<div><p>ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
for (ConsumerRecord&lt;String, String&gt; record : records)</p>
<blockquote>
<div>// print the offset,key and value for the consumer records.
System.out.printf(&#8220;offset = %d, key = %s, value = %sn&#8221;, record.offset(), record.key(), record.value());</div></blockquote>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p class="last">}</p>
</dd>
</dl>
</div>
<div class="section" id="id74">
<h1>}<a class="headerlink" href="#id74" title="Permalink to this headline">¶</a></h1>
<p>![](../../_static/kafka00002.png)</p>
<p>查看Linux里面的消费者，然后再执行生产者的代码，也能看到消费：</p>
<p><code class="docutils literal"><span class="pre">`shell</span>
<span class="pre">bin/kafka-console-consumer.sh</span> <span class="pre">--bootstrap-server</span> <span class="pre">PLAINTEXT://172.16.60.190:9092</span> <span class="pre">--topic</span> <span class="pre">HelloWorld</span> <span class="pre">--from-beginning</span>
<span class="pre">`</span></code></p>
<p>![](../../_static/kafka00003.png)</p>
<p>参考文献</p>
<p>&lt;<a class="reference external" href="https://blog.csdn.net/weixin_42369418/article/details/103234026?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.compare">https://blog.csdn.net/weixin_42369418/article/details/103234026?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.compare</a>&gt;</p>
<p>### 9.用Pyhton来测试Kafka生产者和消费者</p>
<p>&lt;<a class="reference external" href="https://github.com/confluentinc/confluent-kafka-python/tree/master/examples">https://github.com/confluentinc/confluent-kafka-python/tree/master/examples</a>&gt;</p>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, huxiaojian

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>